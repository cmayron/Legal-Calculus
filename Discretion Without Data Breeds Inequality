# **Discretion Without Data Breeds Inequality**

By Charles Mayron, MD

Every state runs its courts its own way. Rules, resources, tech, even language access—discretion is everywhere. We take comfort in the idea that “justice is mostly just,” but the numbers we do have tell a rougher story.

# **What the trendlines already say**

1) Civil cases rarely reach the merits. Across large civil dockets, most cases end in defaults or dismissals rather than a reasoned decision on the facts or law. Courts also struggle to hit their own model time standards. That’s not a courtroom drama; it’s administrative attrition.

2) Volume is massive—and shifting. State courts handled ~67 million filings in 2023—up 4% from 2022 yet still ~30% below 2012. Caseload changes can mask worsening access if we don’t also track how quickly (and how fairly) cases move.

3) Jury trials keep shrinking. The civil jury has become an endangered species, with modern rates measured in fractions of a percent of filings—part of a long decline that predates the pandemic. When trials vanish, informal, discretionary case management fills the vacuum.

4) The justice gap is not theoretical. Low-income Americans get no or insufficient help for ~92% of serious civil legal problems. If most people can’t get help, then “justice for most” is an article of faith, not a measurement.

5) Pro se parties face steeper drop-off. Federal trend work shows persistent, measurable patterns in self-represented litigation—prevalent in certain categories and exposed to early attrition. That should be a red flag for any state measuring fairness.

6) Language access isn’t automatic. The Justice Department recently forced reforms in a state system that failed to provide meaningful access for limited-English-proficient court users. If compliance requires federal intervention, it’s not yet a solved problem.

# **The conclusion hiding in plain sight**

If civil cases end before the merits, if trials are rare, if most people can’t get help, and if language access still needs federal enforcement, then “justice is mostly just” is wishful thinking. In a discretionary system—where “each state does what it wants”—discretion without data predictably hardens into inequality.

The fix is not to erase discretion; it’s to bound it with transparent, comparable metrics.

# **What every state can publish next quarter**

Stop arguing in the abstract. Measure the pipeline people actually experience:

1. Days to Docket & TRO
Set service targets (e.g., docket ≤ 7 days; TRO ≤ 14 days absent extraordinary cause) and publish monthly compliance.
2. Outcome Mix by Representation
Show merits vs. procedural endpoints (default, service, format, jurisdiction) split by pro se vs. represented. If weaponized procedure exists, this is where it will show up.
3. Interpreter Coverage & IFP Grant Rate
Post the share of hearings needing interpreters that had one, and in-forma-pauperis approvals by county.
4. Arbitration Compulsion & Cost Shift
Track motions-to-compel granted/denied and who pays. If compulsion systematically pushes vulnerable parties into worse outcomes, it’s an access issue, not a private preference.
5. Remote & E-Filing Access
Report availability and usage. Remote options—properly implemented—correlate with better participation and public support; measure whether they narrow no-shows and defaults.

Then make it comparable: normalize per-100k population, adopt the NCSC reporting definitions, and publish a composite State Justice Index (Access, Production/Timeliness, Equity Penalty) alongside a case-level Injustice Score for audits. States can tailor weights, but the fields must be public.

# **“But justice is discretionary—judges are the kings.”**

Discretion is not the problem; opacity is. In medicine, surgeon discretion coexists with infection dashboards and time-to-antibiotics standards. No one confuses measurement with micromanagement; we use numbers to learn and improve. Courts can, too.

# **What the country needs to admit**

We believed justice was “mostly just” because we weren’t counting the parts where people fall off: language, money, time, and representation. The data we do have already undermines the myth. The rest is a records request away.

So yes—each state can do what it wants. But each state can also show us what it does. Publish the pipeline. Count the defaults. Track interpreter coverage. Split outcomes by representation. Measure arbitration’s real-world effects. If the numbers prove justice is working, all the better. If not, we’ll finally know where to start.

What gets measured gets managed. Justice is worthy of that humility—and the public is owed nothing less.